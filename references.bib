@article{Legendre2001,
abstract = {This paper examines how to obtain species biplots in unconstrained or constrained ordination without resorting to the Euclidean distance [used in principal component analysis (PCA) and redundancy analysis (RDA)] or the chi-square distance [preserved in correspondence analysis (CA) and canonical correspondence analysis (CCA)] which are not always appropriate for the analysis of community composition data. To achieve this goal, transformations are proposed for species data tables. They allow ecologists to use ordination methods such as PCA and RDA, which are Euclidean-based, for the analysis of community data, while circumventing the problems associated with the Euclidean distance, and avoiding CA and CCA which present problems of their own in some cases. This allows the use of the original (transformed) species data in RDA carried out to test for relationships with explanatory variables (i.e. environ- $\backslash$nmental variables, or factors of a multifactorial analysis-of-variance model); ecologists can then draw biplots displaying the relationships of the species to the explanatory variables. Another application allows the use of species data in other methods of multivariate data analysis which optimize a least-squares loss function; an example is K-means partitioning.},
author = {Legendre, Pierre and Gallagher, Eugene},
doi = {10.1007/s004420100716},
file = {:mnt/eaf0c131-a2f8-4fbc-aacb-cad3e6cf416d/Articles/Legendre{\_}{\&}{\_}Gallagher.pdf:pdf},
isbn = {0029-8549},
issn = {0029-8549},
journal = {Oecologia},
keywords = {Biplot diagram,Canonical correspondence analysis,Correspondence analysis,Principal-component analysis,Redundancy analysis},
month = {oct},
number = {2},
pages = {271--280},
pmid = {1566},
title = {{Ecologically meaningful transformations for ordination of species data}},
url = {http://link.springer.com/10.1007/s004420100716},
volume = {129},
year = {2001}
}
@article{Nguyen2015,
author = {Nguyen, Tan T. and Landfald, Bjarne},
doi = {10.3389/fmicb.2015.00017},
file = {:mnt/eaf0c131-a2f8-4fbc-aacb-cad3e6cf416d/Articles/fmicb-06-00017.pdf:pdf},
issn = {1664-302X},
journal = {Frontiers in Microbiology},
keywords = {16S rRNA gene,Archaea,Bacteria,Barents Sea,Beta-diversity,Sediment},
month = {jan},
number = {JAN},
pages = {1--12},
title = {{Polar front associated variation in prokaryotic community structure in Arctic shelf seafloor}},
url = {http://journal.frontiersin.org/article/10.3389/fmicb.2015.00017/abstract},
volume = {6},
year = {2015}
}
@article{Rellstab2015,
abstract = {Landscape genomics is an emerging research field that aims to identify the environmental factors that shape adaptive genetic variation and the gene variants that drive local adaptation. Its development has been facilitated by next-generation sequencing, which allows for screening thousands to millions of single-nucleotide polymorphisms in many individuals and populations at reasonable costs. In parallel, datasets describing environmental factors have greatly improved and increasingly become publicly accessible. Accordingly, numerous analytical methods for environmental association studies have been developed. Environmental association analysis identifies genetic variants associated with particular environmental factors and has the potential to uncover adaptive patterns that are not discovered by traditional tests for the detection of outlier loci based on population genetic differentiation. We review methods for conducting environmental association analysis including categorical tests, logistic regressions, matrix correlations, general linear models, and mixed effects models. We discuss the advantages and disadvantages of different approaches, provide a list of dedicated software packages and their specific properties, and stress the importance of incorporating neutral genetic structure in the analysis. We also touch on additional important aspects such as sampling design, environmental data preparation, pooled and reduced-representation sequencing, candidate gene approaches, linearity of allele-environment associations, and the combination of environmental association analyses with traditional outlier detection tests. We conclude by summarizing expected future directions in the field, such as the extension of statistical approaches, environmental association analysis for ecological gene annotation, and the need for replication and post-hoc validation studies. This article is protected by copyright. All rights reserved.},
author = {Rellstab, Christian and Gugerli, Felix and Eckert, Andrew J. and Hancock, Angela M. and Holderegger, Rolf},
doi = {10.1111/mec.13322},
file = {:mnt/eaf0c131-a2f8-4fbc-aacb-cad3e6cf416d/Articles/Rellstab{\_}et{\_}al-2015-Molecular{\_}Ecology.pdf:pdf},
isbn = {1365-294X (Electronic)$\backslash$r0962-1083 (Linking)},
issn = {09621083},
journal = {Molecular Ecology},
keywords = {adaptive genetic variation,ecological association,environmental correlation analysis,genetic-environment association,genotype-environment correlation,local adaptation,natural selection,neutral genetic structure,population genomics},
month = {sep},
number = {17},
pages = {4348--4370},
pmid = {26184487},
title = {{A practical guide to environmental association analysis in landscape genomics}},
url = {http://doi.wiley.com/10.1111/mec.13322},
volume = {24},
year = {2015}
}
@article{F.Dormann2007,
abstract = {Species distributional or trait data based on range map (extent-of-occurrence) or atlas survey data often display spatial autocorrelation, i.e. locations close to each other exhibit more similar values than those further apart. If this pattern remains present in the residuals of a statistical model based on such data, one of the key assumptions of standard statistical analyses, that residuals are independent and identically distributed (i.i.d), is violated. The violation of the assumption of i.i.d. residuals may bias parameter estimates and can increase type I error rates (falsely rejecting the null hypothesis of no effect). While this is increasingly recognised by researchers analysing species distribution data, there is, to our knowledge, no comprehensive overview of the many available spatial statistical methods to take spatial autocorrelation into account in tests of statistical significance. Here, we describe six different statistical approaches to infer correlates of species' distributions, for both presence/absence (binary response) and species abundance data (poisson or normally distributed response), while accounting for spatial autocorrelation in model residuals: autocovariate regression; spatial eigenvector mapping; generalised least squares; (conditional and simultaneous) autoregressive models and generalised estimating equations. A comprehensive comparison of the relative merits of these methods is beyond the scope of this paper. To demonstrate each method's implementation, however, we undertook preliminary tests based on simulated data. These preliminary tests verified that most of the spatial modeling techniques we examined showed good type I error control and precise parameter estimates, at least when confronted with simplistic simulated data containing spatial autocorrelation in the errors. However, we found that for presence/absence data the results and conclusions were very variable between the different methods. This is likely due to the low information content of binary maps. Also, in contrast with previous studies, we found that autocovariate methods consistently underestimated the effects of environmental controls of species distributions. Given their widespread use, in particular for the modelling of species presence/absence data (e.g. climate envelope models), we argue that this warrants further study and caution in their use. To aid other ecologists in making use of the methods described, code to implement them in freely available software is provided in an electronic appendix.},
author = {{F. Dormann}, Carsten and {M. McPherson}, Jana and {B. Ara{\'{u}}jo}, Miguel and Bivand, Roger and Bolliger, Janine and Carl, Gudrun and {G. Davies}, Richard and Hirzel, Alexandre and Jetz, Walter and {Daniel Kissling}, W. and K{\"{u}}hn, Ingolf and Ohlem{\"{u}}ller, Ralf and {R. Peres-Neto}, Pedro and Reineking, Bj{\"{o}}rn and Schr{\"{o}}der, Boris and {M. Schurr}, Frank and Wilson, Robert},
doi = {10.1111/j.2007.0906-7590.05171.x},
file = {:mnt/eaf0c131-a2f8-4fbc-aacb-cad3e6cf416d/Articles/Dormann{\_}et{\_}al-2007-Ecography.pdf:pdf},
isbn = {0906-7590},
issn = {09067590},
journal = {Ecography},
number = {5},
pages = {609--628},
pmid = {10378},
title = {{Methods to account for spatial autocorrelation in the analysis of species distributional data: A review}},
volume = {30},
year = {2007}
}
@article{Lyons2016,
author = {Lyons, W. B. and Deuerling, K. and Welch, K. A. and Welch, S. A. and Michalski, G. and Walters, W. W. and Nielsen, U. and Wall, D. H. and Hogg, I. and Adams, B. J.},
doi = {10.1038/srep26189},
file = {:home/paul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lyons et al. - 2016 - The Soil Geochemistry in the Beardmore Glacier Region, Antarctica Implications for Terrestrial Ecosystem History.pdf:pdf},
issn = {2045-2322},
journal = {Scientific Reports},
month = {may},
number = {April},
pages = {26189},
publisher = {Nature Publishing Group},
title = {{The Soil Geochemistry in the Beardmore Glacier Region, Antarctica: Implications for Terrestrial Ecosystem History}},
url = {http://www.nature.com/articles/srep26189},
volume = {6},
year = {2016}
}
@misc{Chen2016,
annote = {R package version 1.2.1.3},
author = {Chen, Wen and Simpson, Joshua and Levesque, C Andre},
institution = {Agriculture and Agri-Food Canada},
title = {{RAM: R for Amplicon-Sequencing-Based Microbial-Ecology}},
url = {http://cran.r-project.org/package=RAM},
year = {2016}
}
@article{VandenBerg2006,
abstract = {BACKGROUND Extracting relevant biological information from large data sets is a major challenge in functional genomics research. Different aspects of the data hamper their biological interpretation. For instance, 5000-fold differences in concentration for different metabolites are present in a metabolomics data set, while these differences are not proportional to the biological relevance of these metabolites. However, data analysis methods are not able to make this distinction. Data pretreatment methods can correct for aspects that hinder the biological interpretation of metabolomics data sets by emphasizing the biological information in the data set and thus improving their biological interpretability. RESULTS Different data pretreatment methods, i.e. centering, autoscaling, pareto scaling, range scaling, vast scaling, log transformation, and power transformation, were tested on a real-life metabolomics data set. They were found to greatly affect the outcome of the data analysis and thus the rank of the, from a biological point of view, most important metabolites. Furthermore, the stability of the rank, the influence of technical errors on data analysis, and the preference of data analysis methods for selecting highly abundant metabolites were affected by the data pretreatment method used prior to data analysis. CONCLUSION Different pretreatment methods emphasize different aspects of the data and each pretreatment method has its own merits and drawbacks. The choice for a pretreatment method depends on the biological question to be answered, the properties of the data set and the data analysis method selected. For the explorative analysis of the validation data set used in this study, autoscaling and range scaling performed better than the other pretreatment methods. That is, range scaling and autoscaling were able to remove the dependence of the rank of the metabolites on the average concentration and the magnitude of the fold changes and showed biologically sensible results after PCA (principal component analysis).In conclusion, selecting a proper data pretreatment method is an essential step in the analysis of metabolomics data and greatly affects the metabolites that are identified to be the most important.},
author = {van den Berg, Robert a and Hoefsloot, Huub C J and Westerhuis, Johan a and Smilde, Age K and van der Werf, Mari{\"{e}}t J},
doi = {10.1186/1471-2164-7-142},
file = {:mnt/eaf0c131-a2f8-4fbc-aacb-cad3e6cf416d/Articles/art{\%}3A10.1186{\%}2F1471-2164-7-142.pdf:pdf},
isbn = {1471-2164},
issn = {1471-2164},
journal = {BMC genomics},
keywords = {Automatic Data Processing,Automatic Data Processing: methods,Cluster Analysis,Databases,Fermentation,Fermentation: genetics,Genetic,Metabolism,Metabolism: genetics,Models,Observer Variation,Oligonucleotide Array Sequence Analysis,Oligonucleotide Array Sequence Analysis: statistic,Pseudomonas putida,Pseudomonas putida: genetics,Reproducibility of Results,Statistical Distributions,Theoretical},
number = {1},
pages = {142},
pmid = {16762068},
title = {{Centering, scaling, and transformations: improving the biological information content of metabolomics data.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16762068 http://bmcgenomics.biomedcentral.com/articles/10.1186/1471-2164-7-142 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC1534033},
volume = {7},
year = {2006}
}
@article{Ranganathan2011,
author = {Ranganathan, Yuvaraj and Borges, Renee M},
doi = {10.4161/psb.6.1.14191},
file = {:mnt/eaf0c131-a2f8-4fbc-aacb-cad3e6cf416d/Articles/psb0601{\_}0113.pdf:pdf},
issn = {1559-2324},
journal = {Plant Signaling {\&} Behavior},
keywords = {auto-correlation,cal ecology,chemi-,compositional data,data,data mining,proportion,random forests,review,transformation},
month = {jan},
number = {1},
pages = {113--116},
title = {{To transform or not to transform}},
url = {http://www.tandfonline.com/doi/abs/10.4161/psb.6.1.14191},
volume = {6},
year = {2011}
}
@article{Noble2009,
abstract = {Most bioinformatics coursework focuses on algorithms, with perhaps some components devoted to learning programming skills and learning how to use existing bioinformatics software. Unfortunately, for students who are preparing for a research career, this type of curriculum fails to address many of the day-to-day organizational challenges associated with performing computational experiments. In practice, the principles behind organizing and documenting computational experiments are often learned on the fly, and this learning is strongly influenced by personal predilections as well as by chance interactions with collaborators or colleagues. The purpose of this article is to describe one good strategy for carrying out computational experiments. I will not describe profound issues such as how to formulate hypotheses, design experiments, or draw conclusions. Rather, I will focus on relatively mundane issues such as organizing files and directories and documenting progress. These issues are important because poor organizational choices can lead to significantly slower research progress. I do not claim that the strategies I outline here are optimal. These are simply the principles and practices that I have developed over 12 years of bioinformatics research, augmented with various suggestions from other researchers with whom I have discussed these issues.},
author = {Noble, William Stafford},
doi = {10.1371/journal.pcbi.1000424},
file = {:mnt/eaf0c131-a2f8-4fbc-aacb-cad3e6cf416d/Articles/journal.pcbi.1000424.PDF:PDF},
isbn = {1553-7358},
issn = {1553734X},
journal = {PLoS Computational Biology},
number = {7},
pages = {1--5},
pmid = {19649301},
title = {{A quick guide to organizing computational biology projects}},
volume = {5},
year = {2009}
}
@article{yeo2000,
author = {Yeo, In-Kwon and Johnson, Richard A.},
file = {:home/paul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yeo, Johnson - 2000 - A new family of power transformations to improve normality or symmetry.pdf:pdf},
journal = {Biometrika},
number = {87},
pages = {954--959},
title = {{A new family of power transformations to improve normality or symmetry}},
url = {http://www.jstor.org/stable/2673623},
volume = {4},
year = {2000}
}
@article{Paulson2013,
abstract = {We introduce a methodology to assess differential abundance in sparse high-throughput microbial marker-gene survey data. Our approach, implemented in the metagenomeSeq Bioconductor package, relies on a novel normalization technique and a statistical model that accounts for undersampling-a common feature of large-scale marker-gene studies. Using simulated data and several published microbiota data sets, we show that metagenomeSeq outperforms the tools currently used in this field.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Paulson, Joseph N and Stine, O Colin and Bravo, H{\'{e}}ctor Corrada and Pop, Mihai},
doi = {10.1038/nmeth.2658},
eprint = {NIHMS150003},
file = {:home/paul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Paulson et al. - 2013 - Differential abundance analysis for microbial marker-gene surveys.pdf:pdf},
isbn = {2122633255},
issn = {1548-7091},
journal = {Nature Methods},
keywords = {16S,16S: genetics,Algorithms,Animals,Area Under Curve,Cluster Analysis,Computer Simulation,DNA,Databases,Gene Expression Profiling,Gene Expression Profiling: methods,Genetic,Genetic Markers,Genetic Variation,Humans,Intestines,Intestines: microbiology,Metagenomics,Metagenomics: methods,Mice,Microbiota,Models,Normal Distribution,Phenotype,RNA,Ribosomal,Sequence Analysis,Software,Statistical},
month = {sep},
number = {12},
pages = {1200--1202},
pmid = {24076764},
title = {{Differential abundance analysis for microbial marker-gene surveys}},
url = {http://dx.doi.org/10.1038/nmeth.2658 http://www.nature.com/doifinder/10.1038/nmeth.2658},
volume = {10},
year = {2013}
}
@article{McMurdie2013,
abstract = {BACKGROUND: the analysis of microbial communities through dna sequencing brings many challenges: the integration of different types of data with methods from ecology, genetics, phylogenetics, multivariate statistics, visualization and testing. With the increased breadth of experimental designs now being pursued, project-specific statistical analyses are often needed, and these analyses are often difficult (or impossible) for peer researchers to independently reproduce. The vast majority of the requisite tools for performing these analyses reproducibly are already implemented in R and its extensions (packages), but with limited support for high throughput microbiome census data. RESULTS: Here we describe a software project, phyloseq, dedicated to the object-oriented representation and analysis of microbiome census data in R. It supports importing data from a variety of common formats, as well as many analysis techniques. These include calibration, filtering, subsetting, agglomeration, multi-table comparisons, diversity analysis, parallelized Fast UniFrac, ordination methods, and production of publication-quality graphics; all in a manner that is easy to document, share, and modify. We show how to apply functions from other R packages to phyloseq-represented data, illustrating the availability of a large number of open source analysis techniques. We discuss the use of phyloseq with tools for reproducible research, a practice common in other fields but still rare in the analysis of highly parallel microbiome census data. We have made available all of the materials necessary to completely reproduce the analysis and figures included in this article, an example of best practices for reproducible research. CONCLUSIONS: The phyloseq project for R is a new open-source software package, freely available on the web from both GitHub and Bioconductor.},
author = {McMurdie, Paul J and Holmes, Susan},
file = {:home/paul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/McMurdie, Holmes - 2013 - Phyloseq An R Package for reproducible interactive analysis and graphics of microbiome census data.pdf:pdf},
isbn = {19326203 (ISSN)},
issn = {19326203},
journal = {PLoS ONE},
keywords = {DNA,Data Interpretation,Humans,Metagenome,Multivariate Analysis,Phylogeny,Principal Component Analysis,Sequence Analysis,Software,Statistical},
month = {jan},
number = {4},
pages = {e61217},
pmid = {23630581},
title = {{Phyloseq: An R Package for reproducible interactive analysis and graphics of microbiome census data}},
volume = {8},
year = {2013}
}
@article{Kuhn2008,
abstract = {The caret package, short for classification and regression training, contains numerous tools for developing predictive models using the rich set of models available in R. The package focuses on simplifying model training and tuning across a wide variety of modeling techniques. It also includes methods for pre-processing training data, calculating variable importance, and model visualizations. An example from computational chemistry is used to illustrate the functionality on a real data set and to benchmark the benefits of parallel processing with several types of models.},
author = {Kuhn, Max},
isbn = {1548-7660},
issn = {15487660},
journal = {Journal Of Statistical Software},
keywords = {model building,networkspaces,parallel processing,r,tuning parameters},
number = {5},
pages = {1--26},
title = {{Building Predictive Models in R Using the caret Package}},
volume = {28},
year = {2008}
}
